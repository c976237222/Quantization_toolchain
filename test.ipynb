{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正准备量化你的网络，检查下列设置:\n",
      "WORKING DIRECTORY    : working\n",
      "TARGET PLATFORM      : TRT_INT8\n",
      "NETWORK INPUTSHAPE   : [1, 3, 224, 224]\n",
      "CALIBRATION BATCHSIZE: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading calibration files: 100%|██████████| 640/640 [00:09<00:00, 65.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 File(s) Loaded.\n",
      "Loaded sample 0, shape: torch.Size([1, 3, 224, 224])\n",
      "Loaded sample 1, shape: torch.Size([1, 3, 224, 224])\n",
      "Loaded sample 2, shape: torch.Size([1, 3, 224, 224])\n",
      "Loaded sample 3, shape: torch.Size([1, 3, 224, 224])\n",
      "Loaded sample 4, shape: torch.Size([1, 3, 224, 224])\n",
      "Batch Shape: torch.Size([64, 3, 224, 224])\n",
      "[17:07:50] PPQ Quantization Fusion Pass Running ...       Finished.\n",
      "[17:07:50] PPQ Quantize Simplify Pass Running ...         Finished.\n",
      "[17:07:50] PPQ Parameter Quantization Pass Running ...    Finished.\n",
      "[17:07:50] PPQ Runtime Calibration Pass Running ...       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration Progress(Phase 1): 100%|██████████| 32/32 [05:42<00:00, 10.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "[17:13:44] PPQ Quantization Alignment Pass Running ...    Finished.\n",
      "[17:13:44] PPQ Passive Parameter Quantization Running ... Finished.\n",
      "[17:13:44] PPQ LSQ Optimization Running ...               \n",
      "Check following parameters:\n",
      "Is Scale Trainable:        True\n",
      "Interested Layers:         []\n",
      "Collecting Device:         cuda\n",
      "Num of blocks:             6\n",
      "Learning Rate:             1e-05\n",
      "Steps:                     500\n",
      "Gamma:                     0\n",
      "\n",
      "# Block [1 / 6]: [/features/features.0/Conv -> /features/features.4/MaxPool]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Tuning Procedure : 100%|██████████| 500/500 [01:06<00:00,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning Finished  : (37.3235 -> 28.6100) [Block Loss]\n",
      "\n",
      "# Block [2 / 6]: [/features/features.5/Conv -> /features/features.9/MaxPool]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Tuning Procedure : 100%|██████████| 500/500 [00:40<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning Finished  : (127.9212 -> 110.3618) [Block Loss]\n",
      "\n",
      "# Block [3 / 6]: [/features/features.10/Conv -> /features/features.14/Conv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Tuning Procedure : 100%|██████████| 500/500 [00:38<00:00, 12.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning Finished  : (746.9162 -> 512.7488) [Block Loss]\n",
      "\n",
      "# Block [4 / 6]: [/features/features.17/Conv -> /features/features.21/Conv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Tuning Procedure : 100%|██████████| 500/500 [00:28<00:00, 17.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning Finished  : (689.6067 -> 268.4885) [Block Loss]\n",
      "\n",
      "# Block [5 / 6]: [/features/features.24/Conv -> /features/features.28/Conv]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Tuning Procedure : 100%|██████████| 500/500 [00:09<00:00, 50.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning Finished  : (314.1484 -> 90.8628) [Block Loss]\n",
      "\n",
      "# Block [6 / 6]: [/classifier/classifier.0/Gemm -> /classifier/classifier.6/Gemm]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Tuning Procedure : 100%|██████████| 500/500 [00:16<00:00, 29.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning Finished  : (8.2988 -> 0.8674) [Block Loss]\n",
      "\n",
      "Finished.\n",
      "[17:17:26] PPQ Passive Parameter Quantization Running ... Finished.\n",
      "[17:17:26] PPQ Parameter Baking Pass Running ...          Finished.\n",
      "--------- Network Snapshot ---------\n",
      "Num of Op:                    [38]\n",
      "Num of Quantized Op:          [38]\n",
      "Num of Variable:              [71]\n",
      "Num of Quantized Var:         [71]\n",
      "------- Quantization Snapshot ------\n",
      "Num of Quant Config:          [108]\n",
      "ACTIVATED:                    [18]\n",
      "BAKED:                        [16]\n",
      "OVERLAPPED:                   [58]\n",
      "FP32:                         [16]\n",
      "Network Quantization Finished.\n"
     ]
    }
   ],
   "source": [
    "from ppq import *                                       \n",
    "from ppq.api import *\n",
    "import os\n",
    "\n",
    "from ppq.utils.TensorRTUtil import build_engine\n",
    "#For vgg16\n",
    "# modify configuration below:\n",
    "WORKING_DIRECTORY = 'working'                             # choose your working directory\n",
    "TARGET_PLATFORM   = TargetPlatform.TRT_INT8          # choose your target platform\n",
    "MODEL_TYPE        = NetworkFramework.ONNX                 # or NetworkFramework.CAFFE\n",
    "INPUT_LAYOUT          = 'chw'                             # input data layout, chw or hwc\n",
    "NETWORK_INPUTSHAPE    = [1, 3, 224, 224]                  # input shape of your network\n",
    "CALIBRATION_BATCHSIZE = 64                                 # batchsize of calibration dataset\n",
    "EXECUTING_DEVICE      = 'cuda'                            # 'cuda' or 'cpu'.\n",
    "REQUIRE_ANALYSE       = False\n",
    "TRAINING_YOUR_NETWORK = True                              # 是否需要 Finetuning 一下你的网络\n",
    "need_accuracy = True\n",
    "label_path = os.path.join(WORKING_DIRECTORY, 'val.txt')\n",
    "graph = None\n",
    "if MODEL_TYPE == NetworkFramework.ONNX:\n",
    "    graph = load_onnx_graph(onnx_import_file = os.path.join(WORKING_DIRECTORY, 'model.onnx'))\n",
    "    \n",
    "assert graph is not None, 'Graph Loading Error, Check your input again.'\n",
    "\n",
    "QS = QuantizationSettingFactory.default_setting()\n",
    "\n",
    "if TRAINING_YOUR_NETWORK:\n",
    "    QS.lsq_optimization = True                                      # 启动网络再训练过程，降低量化误差\n",
    "    QS.lsq_optimization_setting.steps = 500                         # 再训练步数，影响训练时间，500 步大概几分钟\n",
    "    QS.lsq_optimization_setting.collecting_device = 'cuda'          # 缓存数据放在那，cuda 就是放在gpu，如果显存超了你就换成 'cpu'\n",
    "    QS.lsq_optimization_setting.block_size         = 4\n",
    "    QS.lsq_optimization_setting.lr                 = 1e-5\n",
    "    QS.lsq_optimization_setting.gamma              = 0\n",
    "    QS.lsq_optimization_setting.is_scale_trainable = True\n",
    "\n",
    "QS.dispatching_table.append(operation='OP NAME', platform=TargetPlatform.FP32)\n",
    "print('正准备量化你的网络，检查下列设置:')\n",
    "print(f'WORKING DIRECTORY    : {WORKING_DIRECTORY}')\n",
    "print(f'TARGET PLATFORM      : {TARGET_PLATFORM.name}')\n",
    "print(f'NETWORK INPUTSHAPE   : {NETWORK_INPUTSHAPE}')\n",
    "print(f'CALIBRATION BATCHSIZE: {CALIBRATION_BATCHSIZE}')\n",
    "\n",
    "dataloader = load_calibration_dataset(\n",
    "    directory    = WORKING_DIRECTORY,\n",
    "    input_shape  = NETWORK_INPUTSHAPE,\n",
    "    batchsize    = CALIBRATION_BATCHSIZE,\n",
    "    input_format = INPUT_LAYOUT)\n",
    "\n",
    "quantized = quantize_native_model(\n",
    "    setting=QS,                     # setting 对象用来控制标准量化逻辑\n",
    "    model=graph,\n",
    "    calib_dataloader=dataloader,\n",
    "    calib_steps=32,\n",
    "    input_shape=NETWORK_INPUTSHAPE, # 如果你的网络只有一个输入，使用这个参数传参\n",
    "    inputs=None,                    # 如果你的网络有多个输入，使用这个参数传参，就是 input_shape=None, inputs=[torch.zeros(1,3,224,224), torch.zeros(1,3,224,224)]\n",
    "    collate_fn=lambda x: x.to(EXECUTING_DEVICE),  # collate_fn 跟 torch dataloader 的 collate fn 是一样的，用于数据预处理，\n",
    "                                                    # 你当然也可以用 torch dataloader 的那个，然后设置这个为 None\n",
    "    platform=TARGET_PLATFORM,\n",
    "    device=EXECUTING_DEVICE,\n",
    "    do_quantize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10/10 [00:01<00:00,  7.28batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Accuracy: 0.16%\n",
      "0.15625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from vgg_task6 import evaluate_quantized_model\n",
    "result = evaluate_quantized_model(quantized, dataloader, label_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15625\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
